# ğŸ—ï¸ Marketing ML â€“ Local Lakehouse Dashboard

<div align="center">

### End-to-End Marketing Analytics Lakehouse | ğŸ¦† DuckDB | ğŸ¤– ML-Driven Insights | ğŸ“Š Streamlit Dashboard

**Automated data ingestion, ML-driven pacing and conversion modelling, and LM Studio-powered insight generation**

[![Python](https://img.shields.io/badge/Python-3.10--3.13-3670A0?style=flat-square&logo=python&logoColor=ffdd54)](https://www.python.org/)
[![DuckDB](https://img.shields.io/badge/DuckDB-Lakehouse-FFF700?style=flat-square&logo=duckdb&logoColor=000000)](https://duckdb.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?style=flat-square&logo=streamlit&logoColor=white)](https://streamlit.io/)
[![XGBoost](https://img.shields.io/badge/XGBoost-ML-FF6B00?style=flat-square&logo=xgboost&logoColor=white)](https://xgboost.readthedocs.io/)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

</div>

---

## ğŸ“‹ Overview

An end-to-end local marketing analytics lakehouse built with Python, DuckDB, and Streamlit. This project demonstrates a complete data engineering and machine learning pipeline, implementing a bronzeâ†’silverâ†’gold data transformation architecture with automated data ingestion, ML-driven pacing and conversion modelling, and LM Studio-powered insight generation.

### âœ¨ Key Features

- **ğŸ¦† DuckDB Lakehouse Architecture** â€” Bronzeâ†’silverâ†’gold data transformation pipeline
- **ğŸ¤– Machine Learning Models** â€” XGBoost models for conversion prediction and campaign pacing optimisation
- **ğŸ“Š Interactive Dashboard** â€” Streamlit dashboard for real-time analytics and visualisation
- **ğŸ”„ Automated Data Ingestion** â€” Pipeline for processing marketing data from multiple sources
- **ğŸ§  LLM-Powered Insights** â€” LM Studio integration for automated insight generation
- **ğŸ“ˆ Campaign Analytics** â€” Performance tracking, pacing analysis, and conversion modelling

---

## ğŸ—ï¸ Architecture

### Data Pipeline

```
Raw Data (Bronze) â†’ Transformed Data (Silver) â†’ Analytics-Ready (Gold) â†’ ML Models â†’ Dashboard
```

- **Bronze Layer:** Raw CSV data from marketing sources
- **Silver Layer:** Cleaned and standardised data using pandas transformations
- **Gold Layer:** Aggregated and feature-engineered data ready for ML and analytics
- **ML Layer:** XGBoost models for conversion prediction and pacing optimisation
- **Presentation Layer:** Streamlit dashboard for interactive exploration

---

## ğŸš€ Getting Started

### Prerequisites

- **Python:** 3.10â€“3.13
- **Operating System:** macOS or Linux
- **Memory:** Recommended 4GB+ RAM for processing larger datasets

### Installation

1. **Clone the repository:**

```bash
git clone https://github.com/MatthewPaver/marketing-ml-lakehouse.git
cd marketing-ml-lakehouse
```

2. **Create a virtual environment:**

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies:**

```bash
pip install -r lakehouse/requirements.txt
```

### Running the Pipeline

1. **Run the full data pipeline:**

```bash
python -m lakehouse.run_all
```

This will:
- Ingest raw data from `marketing-ml/data/raw/`
- Transform data through bronzeâ†’silverâ†’gold layers
- Train XGBoost models for conversion and pacing
- Generate insights using LM Studio (if configured)

2. **Launch the Streamlit dashboard:**

```bash
PYTHONPATH=$(pwd) streamlit run lakehouse/dashboard/app.py
```

The dashboard will be available at `http://localhost:8501`

---

## ğŸ“Š Data Sources

Raw CSV files are read from `marketing-ml/data/raw/`:

- `audience_segments.csv` â€” Audience segmentation data
- `budget_pacing.csv` â€” Budget pacing and spend tracking
- `conversion_events.csv` â€” Conversion event tracking
- `meta_campaign_performance.csv` â€” Campaign performance metrics

---

## ğŸ› ï¸ Tech Stack

### Core Technologies

- **Python** â€” Primary programming language
- **DuckDB** â€” In-process analytical database for lakehouse architecture
- **pandas** â€” Data manipulation and transformation
- **XGBoost** â€” Gradient boosting for ML models
- **Streamlit** â€” Interactive dashboard framework

### Additional Tools

- **LM Studio** â€” Local LLM integration for insight generation
- **Git LFS** â€” Large file storage for models and datasets

---

## ğŸ“ Repository Structure

```
marketing-ml-lakehouse/
â”œâ”€â”€ lakehouse/              # Main lakehouse pipeline code
â”‚   â”œâ”€â”€ dashboard/          # Streamlit dashboard application
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ run_all.py          # Main pipeline execution script
â”œâ”€â”€ marketing-ml/           # Marketing data and ML components
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ raw/            # Raw CSV data files
â”œâ”€â”€ LICENSE                 # MIT License
â””â”€â”€ README.md              # This file
```

---

## ğŸ”§ Configuration

### Git LFS

Large artefacts (models, DuckDB files, datasets) are tracked using Git LFS:

- `*.pkl` â€” Serialised model files
- `*.duckdb` â€” DuckDB database files

### Data Management

- Raw and intermediate data files are excluded from Git via `.gitignore`
- Only anonymised sample data should be included in the repository
- Model artefacts and large datasets are managed through Git LFS

---

## ğŸ“ˆ Features & Capabilities

### Data Processing

- **Automated Ingestion** â€” Process multiple CSV sources into unified format
- **Data Transformation** â€” Bronzeâ†’silverâ†’gold pipeline with pandas
- **Feature Engineering** â€” Temporal features and aggregations for ML

### Machine Learning

- **Conversion Prediction** â€” XGBoost models to predict conversion likelihood
- **Campaign Pacing** â€” ML-driven pacing optimisation models
- **Forecast Accuracy** â€” Improved forecast reliability through feature engineering

### Analytics & Visualisation

- **Interactive Dashboard** â€” Real-time analytics in Streamlit
- **Campaign Performance** â€” Visualise campaign metrics and trends
- **ML-Driven Recommendations** â€” Actionable insights from model outputs
- **Automated Insights** â€” LLM-generated summaries and recommendations

---

## ğŸ¯ Use Cases

- **Marketing Analytics** â€” Track and analyse campaign performance
- **Conversion Optimisation** â€” Predict and improve conversion rates
- **Budget Management** â€” Optimise campaign pacing and spend allocation
- **Performance Forecasting** â€” ML-driven forecasting for campaign planning
- **Data-Driven Insights** â€” Automated insight generation from campaign data

---

## ğŸ“ Notes

- **Data Privacy:** Only anonymised sample data is included in the repository
- **Model Artefacts:** Large model files are managed through Git LFS
- **Local Processing:** Designed for local development and experimentation
- **Extensibility:** Architecture supports additional data sources and ML models

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ”— Related Projects

- [Marketing ML Lakehouse](https://github.com/MatthewPaver/marketing-ml-lakehouse) â€” This repository
- [Profile](https://github.com/MatthewPaver) â€” View all my projects

---

<div align="center">

**Built with â¤ï¸ using Python, DuckDB, and Streamlit**

[â† Back to Profile](https://github.com/MatthewPaver)

</div>
